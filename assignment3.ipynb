{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EJRuizNtD0p",
        "outputId": "0e9c9eba-b806-435d-bf0d-a6079ea2a139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: R2 Score = 0.9180\n",
            "Fold 2: R2 Score = 0.9146\n",
            "Fold 3: R2 Score = 0.9116\n",
            "Fold 4: R2 Score = 0.9193\n",
            "Fold 5: R2 Score = 0.9244\n",
            "\n",
            "Best Beta (from CV): [1.23161736e+06 2.30225051e+05 1.63956839e+05 1.21115120e+05\n",
            " 7.83467170e+02 1.50662447e+05]\n",
            "Best R2 Score: 0.9243869413350317\n",
            "\n",
            "Final Test R2 Score (with best beta): 0.9146818498916267\n"
          ]
        }
      ],
      "source": [
        "# Q1: K-Fold Cross Validation for Multiple Linear Regression (Least Square Error Fit)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Load Dataset (USA House Price Prediction)\n",
        "url = \"https://drive.google.com/uc?id=1O_NwpJT-8xGfU_-3llUl2sgPu0xllOrX\"  # Direct download link\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# a) Separate features & target\n",
        "X = data.drop(\"Price\", axis=1).values\n",
        "y = data[\"Price\"].values\n",
        "\n",
        "# b) Scale input features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# c) 5-fold division\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_r2 = -np.inf\n",
        "best_beta = None\n",
        "\n",
        "# d) Perform 5-fold CV\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # Least Square Solution (Normal Equation)\n",
        "    # Add a column of ones for the intercept term\n",
        "    X_train_intercept = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "    X_test_intercept = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "    beta = np.linalg.pinv(X_train_intercept.T @ X_train_intercept) @ (X_train_intercept.T @ y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = X_test_intercept @ beta\n",
        "\n",
        "    # R2 Score\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"Fold {fold}: R2 Score = {r2:.4f}\")\n",
        "\n",
        "    if r2 > best_r2:\n",
        "        best_r2 = r2\n",
        "        best_beta = beta\n",
        "\n",
        "print(\"\\nBest Beta (from CV):\", best_beta)\n",
        "print(\"Best R2 Score:\", best_r2)\n",
        "\n",
        "# e) Train with best beta on 70% data, test on 30%\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
        "\n",
        "# Add a column of ones for the intercept term\n",
        "X_train_intercept = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "X_test_intercept = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "\n",
        "# Compute beta again on 70% using Normal Equation\n",
        "beta_final = np.linalg.pinv(X_train_intercept.T @ X_train_intercept) @ (X_train_intercept.T @ y_train)\n",
        "\n",
        "y_pred_final = X_test_intercept @ beta_final\n",
        "final_r2 = r2_score(y_test, y_pred_final)\n",
        "\n",
        "print(\"\\nFinal Test R2 Score (with best beta):\", final_r2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2: Gradient Descent with Validation Set\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Reuse dataset\n",
        "X = data.drop(\"Price\", axis=1).values\n",
        "y = data[\"Price\"].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train (56%), val (14%), test (30%)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_train, X_val, y_temp_train, y_val = train_test_split(X_temp, y_temp, test_size=0.20, random_state=42)\n",
        "# (0.20 of 70% = 14%)\n",
        "\n",
        "# Add bias column\n",
        "X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "X_val   = np.c_[np.ones(X_val.shape[0]), X_val]\n",
        "X_test  = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "\n",
        "# Gradient Descent Function\n",
        "def gradient_descent(X, y, lr, iterations):\n",
        "    m, n = X.shape\n",
        "    beta = np.zeros(n)\n",
        "    for _ in range(iterations):\n",
        "        gradient = -(2/m) * X.T @ (y - X @ beta)\n",
        "        beta -= lr * gradient\n",
        "    return beta\n",
        "\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "best_r2 = -np.inf\n",
        "best_beta = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    beta = gradient_descent(X_train, y_temp_train, lr, 1000)\n",
        "\n",
        "    y_val_pred = X_val @ beta\n",
        "\n",
        "    # Check for inf or NaN in predictions before calculating R2\n",
        "    if np.any(np.isinf(y_val_pred)) or np.any(np.isnan(y_val_pred)):\n",
        "      r2_val = -np.inf\n",
        "    else:\n",
        "      r2_val = r2_score(y_val, y_val_pred)\n",
        "\n",
        "    print(f\"LR={lr} | Val R2={r2_val:.4f}\")\n",
        "\n",
        "    if r2_val > best_r2:\n",
        "        best_r2 = r2_val\n",
        "        best_beta = beta\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_test_pred = X_test @ best_beta\n",
        "final_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "print(\"\\nBest Beta (from validation):\", best_beta)\n",
        "print(\"Final Test R2 Score (with best beta):\", final_r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riPrPYdAt0Um",
        "outputId": "84894539-4dee-443e-db92-6b0217a53c26"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR=0.001 | Val R2=0.6820\n",
            "LR=0.01 | Val R2=0.9098\n",
            "LR=0.1 | Val R2=0.9098\n",
            "LR=1 | Val R2=-inf\n",
            "\n",
            "Best Beta (from validation): [1232618.31836202  230067.95333238  163710.26584918  121680.22876975\n",
            "    2833.37135223  150657.57448494]\n",
            "Final Test R2 Score (with best beta): 0.9147569598865972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3 Car Price Prediction (imports-85)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 1) Load dataset with column names and replace '?' with NaN\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
        "cols = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
        "        \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\",\n",
        "        \"length\", \"width\", \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\",\n",
        "        \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\",\n",
        "        \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "\n",
        "df = pd.read_csv(url, names=cols)\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "# 2) Drop rows where price is NaN (assignment requirement)\n",
        "df = df.dropna(subset=[\"price\"]).copy()\n",
        "# ensure price numeric\n",
        "df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
        "\n",
        "# Helper to convert written numbers (like 'two') to numeric\n",
        "num_map = {\n",
        "    \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\": 6,\n",
        "    \"eight\": 8, \"twelve\": 12\n",
        "}\n",
        "def text_to_number(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    s = str(x).strip().lower()\n",
        "    if s in num_map:\n",
        "        return num_map[s]\n",
        "    try:\n",
        "        return float(s)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# 3(i) Convert 'num_doors' and 'num_cylinders' words to numbers\n",
        "df[\"num_doors\"] = df[\"num_doors\"].apply(text_to_number)\n",
        "df[\"num_cylinders\"] = df[\"num_cylinders\"].apply(text_to_number)\n",
        "\n",
        "# Define which columns to treat as categorical for different encodings\n",
        "label_cols = [\"make\", \"fuel_type\", \"aspiration\", \"engine_location\"]\n",
        "dummy_cols = [\"body_style\", \"drive_wheels\"]\n",
        "special_cols = [\"fuel_system\", \"engine_type\"]\n",
        "\n",
        "# 2 continued: Numeric columns -> convert to numeric and impute median\n",
        "# (treat everything not in label/dummy/special/price as numeric)\n",
        "excluded = set(label_cols + dummy_cols + special_cols + [\"price\"])\n",
        "numeric_cols = [c for c in df.columns if c not in excluded]\n",
        "\n",
        "for c in numeric_cols:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    # central tendency imputation (median for numeric)\n",
        "    med = df[c].median()\n",
        "    df[c].fillna(med, inplace=True)\n",
        "\n",
        "# For categorical label columns: fill NaN with mode then LabelEncode\n",
        "for c in label_cols:\n",
        "    if df[c].isna().any():\n",
        "        mode_val = df[c].mode(dropna=True)\n",
        "        if not mode_val.empty:\n",
        "            df[c].fillna(mode_val[0], inplace=True)\n",
        "        else:\n",
        "            df[c].fillna(\"missing\", inplace=True)\n",
        "    df[c] = LabelEncoder().fit_transform(df[c].astype(str))\n",
        "\n",
        "# 3(ii) Dummy encoding for body_style and drive_wheels - fill NaN first\n",
        "for c in dummy_cols:\n",
        "    if df[c].isna().any():\n",
        "        mode_val = df[c].mode(dropna=True)\n",
        "        if not mode_val.empty:\n",
        "            df[c].fillna(mode_val[0], inplace=True)\n",
        "        else:\n",
        "            df[c].fillna(\"missing\", inplace=True)\n",
        "df = pd.get_dummies(df, columns=dummy_cols, drop_first=True)\n",
        "\n",
        "# 3(iii) special rules:\n",
        "# (iv) fuel_system: contains 'pfi' -> 1 else 0\n",
        "df[\"fuel_system\"] = df[\"fuel_system\"].fillna(\"\").astype(str).str.lower().apply(lambda x: 1 if \"pfi\" in x else 0)\n",
        "\n",
        "# (v) engine_type: con_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGFnalLKuqij",
        "outputId": "dc676b6a-ea26-4071-d096-e13f497be715"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-136062408.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[c].fillna(med, inplace=True)\n"
          ]
        }
      ]
    }
  ]
}